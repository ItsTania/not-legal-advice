{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown\n",
    "\n",
    "import openai\n",
    "import pinecone\n",
    "\n",
    "load_dotenv(Path('../.env')) # Load Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize openai embedding model\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "embed_model = \"text-embedding-ada-002\"\n",
    "\n",
    "res = openai.Embedding.create(\n",
    "    input=[\n",
    "        \"Sample document text goes here\",\n",
    "        \"there will be several phrases in each batch\"\n",
    "    ], engine=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check output and its shape\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in data\n",
    "df = pd.read_csv('/Users/tania/not-legal-advice/data/processed/ACT_law.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pinecone database\n",
    "\n",
    "index_name = 'test'\n",
    "\n",
    "# initialize connection to pinecone\n",
    "pinecone.init(\n",
    "    api_key=os.getenv('PINECONE_API_KEY'),  # app.pinecone.io (console)\n",
    "    environment=os.getenv('PINECONE_ENVIRONMENT')  # next to API key in console\n",
    ")\n",
    "\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # if does not exist, create index\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=len(res['data'][0]['embedding']),\n",
    "        metric='cosine' #'dotproduct'\n",
    "    )\n",
    "# connect to index\n",
    "index = pinecone.Index(index_name)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed stuff\n",
    "\n",
    "# text_fp = ['/Users/tania/not-legal-advice/data/processed/example_1.txt', '/Users/tania/not-legal-advice/data/processed/example_2.txt', '/Users/tania/not-legal-advice/data/processed/example_3.txt']\n",
    "\n",
    "# for file in tqdm(text_fp):\n",
    "#     with open(file, 'r') as f:\n",
    "#         text = f.read()\n",
    "#     res = openai.Embedding.create(\n",
    "#         input=[text], engine=embed_model\n",
    "#     )\n",
    "\n",
    "#     upsert_response = index.upsert(\n",
    "#         vectors=[\n",
    "#         (os.path.basename(file), res['data'][0]['embedding'], {'text': text}),\n",
    "#         ]\n",
    "#         )\n",
    "#     sleep(1)\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    res = openai.Embedding.create(\n",
    "        input=[row['Section_text']], engine=embed_model\n",
    "    )\n",
    "\n",
    "    text_id = row['Act'] + \": \" + row['Section_number']\n",
    "\n",
    "    upsert_response = index.upsert(\n",
    "        vectors=[\n",
    "        (text_id,\n",
    "         res['data'][0]['embedding'], \n",
    "         {\n",
    "        'text': row['Section_text'], \n",
    "        'Act': row['Act'],\n",
    "        'Section_number': row['Section_number'],\n",
    "        'Section_title': row['Section_title']}),\n",
    "        ]\n",
    "        )\n",
    "    sleep(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve Stuff\n",
    "query = \"who is the ATSIEB?\"\n",
    "\n",
    "res = openai.Embedding.create(\n",
    "    input=[query],\n",
    "    engine=embed_model\n",
    ")\n",
    "\n",
    "# retrieve from Pinecone\n",
    "xq = res['data'][0]['embedding']\n",
    "\n",
    "# get relevant contexts (including the questions)\n",
    "res = index.query(xq, top_k=5, include_metadata=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of retrieved text\n",
    "contexts = [item['metadata']['text'] for item in res['matches']]\n",
    "\n",
    "augmented_query = \"\\n\\n---\\n\\n\".join(contexts)+\"\\n\\n-----\\n\\n\"+query\n",
    "\n",
    "print(augmented_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = [str(item['metadata']['Act'] +\": \"+ item['metadata']['Section_number']) for item in res['matches']]\n",
    "print(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system message to 'prime' the model\n",
    "primer = f\"\"\"You are Q&A bot. A highly intelligent system that answers\n",
    "user questions based on the information provided by the user above\n",
    "each question. If the information can not be found in the information\n",
    "provided by the user you truthfully say \"I don't know\".\n",
    "\"\"\"\n",
    "\n",
    "res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": primer},\n",
    "        {\"role\": \"user\", \"content\": augmented_query}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(res['choices'][0]['message']['content']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01c331ff76b2a0c76dd007cca8cb7c7b0a6ec9a23578f93c21b5dc54cb4ddf86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
